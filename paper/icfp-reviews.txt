----------------------- REVIEW 1 ---------------------
PAPER: 32
TITLE: Auto in Agda: Programming proof search
AUTHORS: Pepijn Kokke and Wouter Swierstra


----------- REVIEW -----------
I'm undecided about my overall opinion of this paper -- slightly positive or slightly negative?  The paper organization and writing are very good.  The general research area seems quite important.  The motivation for this particular approach is moderately convincing, but I think the biggest weakness of the paper is not explaining well enough, early enough why this approach is a good idea, as compared to many others that could be taken in Agda or related systems.

Here's my restatement of the paper's setting: Agda is mostly designed for programming, not mathematical theorem-proving.  However, sometimes it is still useful to prove theorems, encoded via Curry-Howard.  These theorems have tended to be small ones, because of how painful it is to write proof terms manually.  Some ad-hoc proof search features are built into Agda, but there is clear aesthetic motivation, if nothing else, for moving more of that functionality into Agda libraries.  In particular, one can take advantage of standard reflection features in Agda, to quote the syntax of the language itself into an algebraic datatype.  A proof-generating Prolog-style search procedure can be coded on top of that datatype (though, to prove termination, we want to translate to a slightly different, more dependent representation first).

It's good to gather experience with many different angles of attack on key problems in dependently typed programming and proving.  I appreciate this paper for trying an angle that I haven't seen before.  At the same time, I feel like the motivation is weak for this particular choice.  The details make for something of a pearl-style worked Agda example, which may be a good sort of thing to see presented at ICFP, but I'm not convinced of the practical value.

As motivation, the authors bring up the Curry-Howard principle of encoding proofs as programs, more or less assuming that readers will agree that a mathematical connection implies something about practical choices in programming-language design.  I personally don't buy it.  There are many very elegant programs written in multiple languages, and this paper doesn't give me any reason to reconsider the appropriateness of separate languages for programming and tactic-based proving.  Again, the authors basically seem to assume that the ICFP audience already agrees with them, and they may be right for most readers, just not me!

There are well-established benefits to implementing proof procedures inside of type theory.  For instance, in proof by reflection, it's possible to prove a procedure correct, rather than forcing it to output a proof term each time it's run.  This paper doesn't follow that approach.  What we have is mostly conventional functional code implementing proof search by manipulating ASTs, with types just a little more sophisticated than Haskell's or OCaml's.  My understanding is that the fancier types are _only_ used here to support automated proof of termination by the Agda system (plus a bit more help catching some bugs at compile time).  No attempt is made at more precise static reasoning about "auto".

Is that delta of static reasoning really worth the complexity of this implementation?  It's hard for me to see why we're so much better off than we would be implementing this code as Haskell plugins to Agda, or as Agda without termination checking.  And, of course, there's the Ltac solution (use a distinct tactic language), if you want to include proof-search code inline within Agda files.

By the way, for an example of verified tactics in type theory with hint databases, see the upcoming ITP 2014 paper by Malecha et al.  It _is_ a feasible option, so it's worth comparing against.

Reading the details of the Agda types and functions used to implement "auto", it was hard for me to figure out what was surprising about it all, what was the "research contribution."  Is there something about the details that an Agda expert wouldn't be able to reconstruct in reasonable time after reading a one-paragraph outline of your approach?  If so, maybe you could highlight those choice points more effectively, in one place and/or with notes during the detailed exposition.

I find the "exists" syntax to be a bit ugly when followed by a lambda abstraction.  Why not combine "exists" and "lambda" in one notation?

Page 1:
"makes the several" shouldn't have "the"

Page 2:
"with a its"
"to to"
"provided it the hint": remove "it"
Some inconsistency in "database" vs. "data base"
"this term, then gives": I would remove the comma.

Page 4:
"these inject and raise to define": add "functions" before "to"
"The SearchSpace[s] resulting: add letter
Definition of "next": Isn't there something funky going on in calling "injectTerm" in the "goal'" definition?  It seems like Agda is implicitly using associativity of addition!

Page 5:
I don't like the quotes around "fresh."  Smartquotes instead?
"recursive call to go": wrong font for "go"?
For non-Agda experts, it is confusing here to introduce the "snoc" operator with its "r" superscript, in a context that also introduces "r" as a local variable!
"to make it match the variable domain": not clear what "it" is here.

Page 6:
"to produce[d]": add character
"the our"
"that the toProofTerms": add "function" or drop "the"

Page 8:
"splitTerm and initLast function[s]": add letter

Page 9:
"a type classes"

Page 10:
Add comma after "necessary to complete the proof"
Add letter: "This difficult[y]" -- and other words missing in the same sentence.
Remove first word: "does no longer needs"
"In contrast to the proof search presented here...": this isn't a complete sentence.


----------------------- REVIEW 2 ---------------------
PAPER: 32
TITLE: Auto in Agda: Programming proof search
AUTHORS: Pepijn Kokke and Wouter Swierstra


----------- REVIEW -----------
The authors present a proof search tactic (auto) for Agda.  Unlike
most auto tactics in the literature, the one presented here is encoded
in the language of Agda itself, instead of in a different language.
The authors manage to escape the restrictions of the pure language of
Agda by using the reflection mechanism of the language.

To summarize my opinion: this paper presents a nice programming
example exploiting the reflection mechanism of Agda, but besides that
it doesn't significantly add knowledge to the area of meta-programming
in proof assistants.

Let me start on a positive note.  I found the work well written, and I
enjoyed the detailed explanation of the code for the prolog
interpreter.  This prolog interpreter is the heart of the auto tactic,
and the authors implemented it in Agda.  Since the interpreter is
inherently non-terminating, and Agda is a pure language, they use a
combination of inductive and co-inductive types to circumvent this
restriction.  On this regard, however, I have a question: what is the
need of co-induction if anyway the search is limited by a natural
number of steps?  Is it just a matter of having a cleaner code, or
there is a more fundamental reason?

That said, apart from the prolog interpreter, I don't find that there
is enough motivation and novelty in this work to justify it being
published in these proceedings.  To start with, an auto tactic was
already built in constructive type theory (CTT) using reflection.
Indeed, in Malecha et al. (2013) and Malecha et al. (2014), not only
they present an auto tactic for Coq using reflection but, moreover,
the use of reflection is pushed one step further to obtain shorter
proof terms, and as such, better overall performance.

Given that this work does not focus in performance, then one must
ask what is the benefit of using reflection.  The use of reflection
indeed comes at a price: one must encode the terms using an
uncomfortable de Bruijn representation, and one is usually limited to
some constructs of the language (the authors are honest about this in
the "Restrictions" paragraph).  Instead, recent approaches like
Gonthier et al. (2013) and Ziliani et al. (2013) permit
meta-programming in CTT without having to use reflection.  The work by
Gonthier et al. (2013) goes in the other direction: they encode
meta-programs using the prolog engine built in the canonical structure
mechanism of Coq.  In Ziliani et al. (2013) they present a new
language, Mtac, encoded as a Coq datatype, to build tactics.  In both
cases tactics are built using the language of Coq (within a specific
DSL).  I don't think there is enough discussion in the paper to
justify the decision of going through reflection instead of using one
of these approaches.

BTW, the authors wrongly point out that Mtac is built on top of Ltac.
Similarly to the quoteGoal primitive of Agda, Mtac has its own
primitive, run, written in Ocaml.  This is the only extra-logical
component, and as such, all of the restrictions that the authors
rightfully mention about Ltac are not present in Mtac.

As a concluding remark, and in response to the following quote:

"The central philosophy of Martin-Löf type theory is that the
construction of programs and proofs is the same activity. Any
external language for proof automation renounces this philosophy.
This paper demonstrates that proof automation is not inherently
at odds with the philosophy of type theory. Paraphrasing Martin-
Löf [14], it no longer seems possible to distinguish the discipline
of programming from the construction of mathematics."

I would like to point out that this idea is already present in many
works.  I can trace it back to the work of Allen et al. (1990), and
more recently to the work of Devriese and Piessens (2013).  What's
more, most of the aforementioned works also make this point.

References:

* Allen, S.F.; Constable, R.L.; Howe, D.J. and Aitken, W.E. 1990. The
semantics of reflected proof. In LICS '90.

* Devriese, D. and Piessens, F. 2013. Typed syntactic
meta-programming. In ICFP '13.

* Gonthier, G.; Ziliani, B.; Nanevski, A., and Dreyer, D. 2013. How to
make ad hoc proof automation less ad hoc. In JFP '13.

* Malecha, G.; Chlipala, A.; Braibant, T.; Hulin, P.; Yang, E. Z.
2013. MirrorShard: Proof by computational reflection with verified
hints. In arXiv:1305.6543.

* Malecha, G.; Chlipala, A.; Braibant. 2014.
Compositional computational reflection.  To appear in ITP 2014.
http://adam.chlipala.net/papers/MirrorShardITP14/

* Ziliani, B.; Dreyer, D.; Krishnaswami, N. R.; Nanevski, A. and
Vafeiadis, V. 2013. Mtac: a monad for typed tactic programming in Coq.
In ICFP '13.


----------------------- REVIEW 3 ---------------------
PAPER: 32
TITLE: Auto in Agda: Programming proof search
AUTHORS: Pepijn Kokke and Wouter Swierstra


----------- REVIEW -----------
The paper describes a proof search algorithm implemented in Agda. The algorithm
is hooked up to Agda's reflection mechanism making it possible to use as a
tactic for searching for (first-order) proofs inside Agda.

I believe internalizing the tactic language is the right approach to automation
for dependently typed languages so it's nice to see papers exploring this. The
implementation of the proof search is quite elegant and well-presented. However,
the paper suffers a little bit from a lack of good applications--the type class
example requires a bit too much boilerplate to be convincing, and the fact that
Agda's compile-time evaluator is not very efficient means that the
implementation is more a proof-of-concept than anything practically useful.

Section 1

  You say that Ltac programs can be inefficient, but it's not clear why your
  approach would be more efficient (clearly, at the moment, it isn't).

  this paper makes [the several] novel contributions
    "several" or "the following"

Section 2

  When introducing unquote mention that the Term is type checked before being
  spliced in.

  ... replacing it with [/a] its concrete syntax.

  ... provided [/it] the hint database contains ...

Section 3

  In Terms and Rules: explain "Fin n" in the definition of ProglogTerm.

  The definition of AddOne does not type check for two reasons:
    - con is applied to One, which is a ProglogTerm and not a TermName, and
    - if you replace con One [] by One, it still has the wrong number of free
      variables.

  Figure 1 should start counting the elements of Fin 3 and Fin 4 from zero rather
  than one.

  At the end of Setting up the search space you mention that every rule
  application adds its own set of free variables. Can you say something more
  about the potential performance issues arising from this? Do you think it
  won't be a problem, or is it something you could fix with a bit more work?

  In the definition of dfs: since you use concatMap instead of >>=, also use
  x :: [] instead of return x.

Section 4

  To use such an interpreter to produce[/d] proof terms, ...

Section 5

  The type of Error should be Set -> Set.

  In Constructing rules:

    we will convert a Name to [the ProglogTerm corresponding to its type/its
    corresponding ProglogTerm]

    Explain why you suddenly use Vec instead of List. I guess it's because of
    initLast. Also explain the type of initLast: what does it return?

    The indentation in toRule is confusing. The bar in the last two clauses
    should be indented more.

  In Reification of proof terms

    The ProofTerm may contain two kinds of [rule names/variables] ...
    (ProofTerms don't have variables)

Section 6

  In the final example you say that the type of 'instance' is inferred. This
  seems suspicious to me. Is it inferred because it's the only thing that could
  possibly have the type you need? What happens if you need two instances?

  The example is not very convincing. Without the automation you would write

    example = ...
      where
        instance = ShowEither ShowBool ShowN

  which is both shorter and does not rely on the type being magically inferred
  from the required instance.

Section 7

  In Performance:

    You blame Agda's poor compile-time evaluation for the bad performance of the
    auto function. While that's quite possibly the main culprit, I don't believe
    it's the only one. It would be fitting to discuss possible optimizations of
    your implementation at this point.

    Another potential performance problem is the use of unquote, which requires
    type checking of the generated proof term. What would be involved in getting
    rid of unquote in your case? Is it at all possible?

  In Restrictions:

    Not all useful hints, however, have [/a] such a Name, ...

  In Refinements:

    You say that you would like to generate incomplete proofs, but that it's
    hard with the current reflection mechanism. Couldn't you generate an
    incomplete proof as a function from the missing parts to the conclusion. The
    user would then have to write

      quoteGoal g in unquote (incompleteAuto ...) ?

    and fill in the ? with whatever the solver hasn't managed to solve.

  In Related work:

    I believe Idris has a reflection-based tactic language that lets you write
    tactics as Idris code.


----------------------- REVIEW 4 ---------------------
PAPER: 32
TITLE: Auto in Agda: Programming proof search
AUTHORS: Pepijn Kokke and Wouter Swierstra


----------- REVIEW -----------
Summary:

This paper shows a new implementation of an 'auto' tactic for Agda. Unlike the
built-in 'auto' tactic "Agsy", written in Haskell, the new tactic described
here is written in the Agda language itself, thanks to the use of Agda's
reflection mechanism.

The first step described is the implementation of a first order solver, fairly
similar to a Prolog solver. This solver is a proof search up to a given depth,
parametrised by the search strategy (breadth-first search, depth-first search,
heuristic-driven...). The key part of this solver is a first order unification
algorithm.

Later on, the authors describe a mechanism which enables to keep the track of
the applied rules, which will help for the construction of the proof term.

Afterwards, they describe the reflection mechanism, which includes both
metaification (going from Agda's built-in terms to the data types used by their
implementation) and reification, which converts the witness obtained by their
proof search into an Agda term : the proof they wanted to obtain.

The last section describes how to implement typeclasses in Agda, using the
tactic that they have implemented.

Review:

The approach of implementing the tactic in the Agda language itself is promising.
This has various positive effects, described by the authors, including:

- increased reusability and possibility of customization of the tactic for
  specific needs
- the fact that you can use the expressivity of Agda (and thus the power of
  full dependent types) in order to develop the tactic.

Nevertheless, this implementation has various limitations, and to my point of
view, the worst of them is that their tactic is untyped, which implies that the
authors can't prove the soundness of their 'auto' method in the system.  This
is quite sad, because writing the tactic in Agda potentially brings the
possibility to reason about it *in* the language, possibily that you don't have
when you implement it in Agda's host language -Haskell- (as this is the case
for "Agsy"). The authors admit these limitations and discuss them.

The main drawback of this paper is the lack of pedagogy in the description of
the various datatypes and functions. They present them before giving enough of
an intuition, which makes it quite hard to read. The worst part is probably the
"next" function on page 4, and the "mkTree" and "dfs" functions on page 5. I
think that more time should be spent to develop the intuition behing these
functions, before giving their precise definitions.

At the same time, the authors have wasted some space with a big diagram (Figure
1), which describes the "inject" and the "raise" functions for Fin, which are
not hard to understand at all, nor specific to their development. This space
would be better used to describe the difficult parts of their implementation.

The lack of examples for all the intermediate functions is another big problem,
and is probably one possible explanation of the previous problem. For the hard
functions mentionned just above, showing first the expected results on a few
terms could help a lot to build an intuition.

My conclusion is that the idea of the authors is interesting, and constitutes
an original contribution, but needs more details and good examples to be fully
understandable in all details.
